{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "859a94b8",
   "metadata": {},
   "source": [
    "<h1 align=\"center\"><b>Financial Sentiment Predict\n",
    "</b></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9099ce64",
   "metadata": {},
   "source": [
    "## **Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "372c6d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Load model & labels \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "from tensorflow.keras.layers import TextVectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac409a6d",
   "metadata": {},
   "source": [
    "## **Modelling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4654d4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP = \"impr2\"\n",
    "MODEL = f\"model_{EXP}.keras\"\n",
    "VOCAB = f\"vocab_{EXP}.txt\"\n",
    "CFG   = f\"tv_cfg_{EXP}.json\"\n",
    "LABEL = f\"class_names_{EXP}.npy\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92feb25b",
   "metadata": {},
   "source": [
    "- Menentukan nama file yang akan dipakai untuk load model, vocabulary, konfigurasi, dan label.\n",
    "- Supaya konsisten, cukup ganti EXP (experiment name), maka semua file terkait ikut berubah."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec0fdfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(MODEL)\n",
    "idx2label = np.load(LABEL, allow_pickle=True).tolist() \\\n",
    "    if os.path.exists(LABEL) else ['negative','neutral','positive']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fb2303",
   "metadata": {},
   "source": [
    "- load_model(MODEL) → memuat model .keras yang sudah disimpan.\n",
    "- np.load(LABEL...) → load file label (class_names_impr2.npy) supaya tahu urutan kelas (misalnya 0=negative, 1=neutral, 2=positive).\n",
    "- Kalau file label tidak ada → default pakai list ['negative','neutral','positive']."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff0fc55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "e2e = (model.inputs[0].dtype == tf.string) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fca360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizer OK | vocab_size: 9548 | max_len: 48\n"
     ]
    }
   ],
   "source": [
    "s = pd.read_csv(\n",
    "    VOCAB,\n",
    "    header=None,\n",
    "    names=[\"tok\"],\n",
    "    dtype=str,           \n",
    "    keep_default_na=False, \n",
    "    na_filter=False        \n",
    ")\n",
    "\n",
    "vocab = s[\"tok\"].astype(str).str.strip()\n",
    "vocab = vocab[vocab != \"\"].tolist()\n",
    "\n",
    "oov_set = {\"[unk]\", \"<unk>\", \"unk\"}\n",
    "if vocab and vocab[0].lower() in oov_set:\n",
    "    vocab = vocab[1:]\n",
    "\n",
    "cfg = json.load(open(CFG, \"r\"))\n",
    "\n",
    "text_vectorization = TextVectorization(\n",
    "    max_tokens=None,                             \n",
    "    standardize=cfg[\"standardize\"],\n",
    "    split=cfg[\"split\"],\n",
    "    output_mode=cfg[\"output_mode\"],\n",
    "    output_sequence_length=cfg[\"max_len\"],\n",
    ")\n",
    "text_vectorization.set_vocabulary(vocab)\n",
    "\n",
    "print(\"Vectorizer OK | vocab_size:\", len(vocab), \"| max_len:\", cfg[\"max_len\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b1ac7c",
   "metadata": {},
   "source": [
    "- Membaca file vocabulary (vocab_impr2.txt) hasil dari training sebelumnya, setiap kata/token disimpan sebagai kolom \"tok\".\n",
    "- Membersihkan vocabulary (hapus spasi kosong, hilangkan token kosong), lalu konversi ke list Python.\n",
    "- Mengecek apakah token pertama adalah OOV token ([unk], <unk>, atau unk), kalau iya maka dibuang.\n",
    "- Membaca konfigurasi preprocessing (tv_cfg_impr2.json) yang berisi parameter max_len, standardize, split, dll.\n",
    "- Membangun ulang layer TextVectorization dengan konfigurasi dan vocabulary yang sama persis dengan saat training, supaya model inference konsisten.\n",
    "- Mengecek apakah vectorizer sudah berhasil dibuat dengan benar, serta menampilkan jumlah vocabulary dan panjang sequence maksimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c7a6b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded!\n"
     ]
    }
   ],
   "source": [
    "EXP = \"impr2\"\n",
    "model = load_model(f\"model_{EXP}.keras\")\n",
    "print(\"Model loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd684b8",
   "metadata": {},
   "source": [
    "- Menentukan nama eksperimen (impr2).\n",
    "- Memuat model yang sudah disimpan sebelumnya (model_impr2.keras).\n",
    "- Mengecek apakah model berhasil dimuat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8133c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"Revenue jumped and management raised full-year guidance.\",\n",
    "    \"Profit declined sharply and the outlook remains weak.\",\n",
    "    \"Shares were little changed following the announcement.\",\n",
    "    \"Customer demand is strong and margins improved this quarter.\",\n",
    "    \"The company cut its forecast due to softer sales.\",\n",
    "    \"Analysts expect stable performance with limited upside.\",\n",
    "    \"New product launch exceeded expectations across regions.\",\n",
    "    \"Operational issues led to delays and higher costs.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a963794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text : Revenue jumped and management raised full-year guidance.\n",
      "pred : positive | probs: [0.0836 0.0327 0.8836]\n",
      "------------------------------------------------------------\n",
      "text : Profit declined sharply and the outlook remains weak.\n",
      "pred : neutral | probs: [0.2346 0.6622 0.1032]\n",
      "------------------------------------------------------------\n",
      "text : Shares were little changed following the announcement.\n",
      "pred : neutral | probs: [0.3554 0.4494 0.1953]\n",
      "------------------------------------------------------------\n",
      "text : Customer demand is strong and margins improved this quarter.\n",
      "pred : positive | probs: [0.0395 0.0145 0.9461]\n",
      "------------------------------------------------------------\n",
      "text : The company cut its forecast due to softer sales.\n",
      "pred : positive | probs: [0.2454 0.1903 0.5643]\n",
      "------------------------------------------------------------\n",
      "text : Analysts expect stable performance with limited upside.\n",
      "pred : positive | probs: [0.2456 0.2936 0.4608]\n",
      "------------------------------------------------------------\n",
      "text : New product launch exceeded expectations across regions.\n",
      "pred : positive | probs: [0.1062 0.0554 0.8384]\n",
      "------------------------------------------------------------\n",
      "text : Operational issues led to delays and higher costs.\n",
      "pred : positive | probs: [0.1491 0.0556 0.7953]\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# vectorize -> predict\n",
    "X = text_vectorization(np.array(texts)).numpy()   # TV sudah direbuild sebelumnya\n",
    "probs = model.predict(X, verbose=0)\n",
    "preds = probs.argmax(1)\n",
    "\n",
    "for t, p, pr in zip(texts, preds, probs):\n",
    "    print(\"text :\", t)\n",
    "    print(\"pred :\", idx2label[int(p)], \"| probs:\", np.round(pr, 4))\n",
    "    print(\"-\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f24972",
   "metadata": {},
   "source": [
    "**Kesimpulan Inference**\n",
    "1. Model kuat dalam mendeteksi sentimen positif (contoh: “revenue jumped”, “customer demand strong”) dengan probabilitas tinggi dan konsisten.\n",
    "2. Namun, banyak kesalahan pada kalimat bernuansa negatif, yang sering diprediksi sebagai positif atau netral.\n",
    "3. Pada kalimat netral, model kadang bingung jika ada campuran kata positif/negatif ringan, sehingga hasil prediksi kurang stabil.\n",
    "4. Secara umum: inference ini menunjukkan bahwa model masih bias ke kelas positif, sehingga perlu perbaikan dataset (balancing kelas negatif & netral) atau penambahan fitur linguistik untuk menangkap nuansa negatif secara lebih baik."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
